# Kuka-VR
Leveraging VR and Force-Haptic Feedback for an Effective Training with Kuka Robots

The proposed framework integrates Virtual Reality (VR) technologies with force and haptic feedback equipment to achieve an effective traiing with robots. This framework aims to simulate realworld scenarios and human-robot collaboration tasks, with the goal of familiarizing users with the aforementioned technologies, overcoming risks that may arise, and enhancing the effectiveness of their training

The combination of a Virtual Environment that utilizes 3d model of Kuka and usage of SenseGloves (Gloves deployed on VR that provide force and haptic feedback) will allow workers to familirize with manual procedures as well as overcome potential risks while handling with high expensive and sensitive mechanisms (Kuka robot) and hence to ensure the carefulness when the actual task on the real robot has to be happened.

The prosed training procedured was utilized using  The necessary equipment for the proposed training procedure, the following hardware was utilized:
- HTC VR Headset
- Sense Gloves
- Vive Trackers

A Virtual Environment of a cricket insect farm was created to replicate real case scenarios and train farm workers, as shown on the image below.

<p align="center">
  <img src="https://github.com/pkatranitsiotis/Kuka-VR/assets/101392986/7135b1d9-429a-4b77-80ee-35c3649ba5ab" width="550" title="hover text">
</p>

Utilizing the SenseGloves technology, users are capable of manipulating the Kuka Robot within a virtual reality (VR) environment, replicating real-life interactions, by applying force adn haptic feedback on user's hands and receiving comprehensive training regarding robot's inverse kinematics and joint limitations as shown on the image below.

<p align="center">
  <img src="https://github.com/pkatranitsiotis/Kuka-VR/assets/101392986/b86ec2e8-5818-4832-be22-9c0480cf6b1d" width="550" title="hover text">
</p>

![Picture1](https://github.com/pkatranitsiotis/Kuka-VR/assets/101392986/b86ec2e8-5818-4832-be22-9c0480cf6b1d)

Therefore the user can be able to feel and touch all the objects objects in VR and apply the corresponding tasks to achieve his effective training. Tasks such as pick and place important objects on the insect crate (like watering tank and feeding tray) as well as manually manipulating the Kuka Robot to scan the crate (Lower down the end effector and scan the crate). Furthermore, a table with two VR buttons has been installed within the interaction VR area. The main objective of these buttons is to record the robotâ€™s movement and display it on the corresponding VR screen. Therefore, the users and their trainees can evaluate the task and identify the optimal robot manipulation movement for this specific task.

A represantion of such a procedure is shown on the following video.

<p align="center">
  <img src="https://github.com/pkatranitsiotis/Kuka-VR/assets/101392986/494955b2-7bc2-4869-bfd4-109947ab8466" width="550" title="hover text">
</p>

![ezgif com-video-to-gif (2)](https://github.com/pkatranitsiotis/Kuka-VR/assets/101392986/494955b2-7bc2-4869-bfd4-109947ab8466)


